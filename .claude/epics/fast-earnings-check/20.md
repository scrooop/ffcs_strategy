---
name: Update documentation (README_TT.md, CLAUDE.md)
status: open
created: 2025-10-19T23:56:22Z
updated: 2025-10-20T00:07:22Z
github: https://github.com/scrooop/ffcs_strategy/issues/20
depends_on: [16, 17, 18, 19]
parallel: true
conflicts_with: []
---

# Task: Update documentation (README_TT.md, CLAUDE.md)

## Description

Update all project documentation to reflect v2.1 changes: fast earnings check, cache behavior, new CSV schema, and CLI flag removal. Ensure users understand the performance improvements and new features.

**Key documentation changes:**
- Add "Performance" section explaining fast earnings check
- Update CLI examples to remove `--skip-earnings` flag
- Document cache location and management
- Update CSV schema documentation (29 columns)
- Add troubleshooting section for cache issues
- Create new `.cache/README.md` for cache management

## Acceptance Criteria

- [ ] `scripts/README_TT.md` updated with v2.1 changes
- [ ] `CLAUDE.md` updated with cache behavior and performance notes
- [ ] New file: `.cache/README.md` with cache management guide
- [ ] CSV schema documentation shows 29 columns (including earnings_source)
- [ ] All CLI examples remove `--skip-earnings` flag
- [ ] Performance expectations documented (1000 symbols: 8min → <30s)
- [ ] Cache troubleshooting section added (how to clear cache, corruption recovery)
- [ ] Migration guide for users upgrading from v2.0

## Technical Details

### File 1: `scripts/README_TT.md`

**Sections to add/update:**

**New section: "Performance Improvements (v2.1)"**
```markdown
## Performance Improvements (v2.1)

The scanner now uses a fast earnings pre-filter with caching to eliminate 80-95% of scan runtime during heavy earnings weeks.

**Key features:**
- **Yahoo Finance as primary source:** Fast earnings date lookup (~100ms vs 500ms TastyTrade)
- **SQLite persistent cache:** Instant lookups for previously scanned symbols
- **Pipeline reordering:** Filter symbols BEFORE expensive TastyTrade API calls

**Performance impact:**
- 1000-symbol scan: ~8 minutes → <30 seconds (during heavy earnings weeks)
- Same-day rescans: <1 second for cached symbols
- Cache hit rate: >90% for daily scanning workflows

**Cache location:** `.cache/earnings.db` in project root
- Safe to delete manually: `rm .cache/earnings.db` (will rebuild automatically)
- See `.cache/README.md` for cache management details
```

**Update "Command Line Flags" section:**
- Remove `--skip-earnings` (no longer exists)
- Update `--allow-earnings` description
- Add note about default behavior

**Update "CSV Output Schema" section:**
- Show 29 columns (add `earnings_source`)
- Update example CSV row

**Add "Troubleshooting" section:**
```markdown
## Troubleshooting

### Cache Issues

**Problem:** Scanner is slow even with cache
**Solution:** Check cache hit rate in console output. If low, cache may be corrupted.
  ```bash
  rm .cache/earnings.db  # Clear cache
  ```

**Problem:** Earnings dates seem stale
**Solution:** Cache automatically refreshes when dates pass. For manual refresh:
  ```bash
  rm .cache/earnings.db  # Force re-fetch all earnings
  ```

**Problem:** "SQLite database locked" error
**Solution:** Another process is using the cache. Wait or kill other scanner instances.
```

### File 2: `CLAUDE.md`

**Sections to update:**

**Update version note:**
```markdown
**Version:** 2.1 - Fast earnings check with caching for 80-95% runtime reduction
```

**Update "Earnings Filtering" section to "Fast Earnings Check (v2.1)":**
```markdown
## Fast Earnings Check (v2.1)

The scanner uses a multi-source earnings data pipeline with persistent caching:

**Data sources (in priority order):**
1. **SQLite cache:** Instant lookup for previously scanned symbols
2. **Yahoo Finance:** Fast primary source (~100ms per symbol) via yfinance
3. **TastyTrade API:** Fallback for Yahoo Finance failures (~500ms per symbol)

**Cache behavior:**
- Location: `.cache/earnings.db` (SQLite database)
- Invalidation: Re-fetch when cached date has passed
- Persistence: Survives restarts, shared across scans
- Management: Safe to delete manually (rebuilds automatically)

**Performance targets:**
- 1000 symbols, 90% cache hit rate: <5s earnings check
- 1000 symbols, 0% cache hit rate (cold start): <30s earnings check
- Overall scan improvement: 80-95% runtime reduction during heavy earnings weeks

**CSV output tracking:**
- `earnings_source` column tracks data provenance ("cache" | "yahoo" | "tastytrade")
- `earnings_date` column shows next earnings date (YYYY-MM-DD)
- `earnings_conflict` column shows yes/no (conflict detected)
```

**Update "Running the Scanner" section:**
- Remove all examples using `--skip-earnings`
- Update help text examples

### File 3: `.cache/README.md` (NEW)

**Create new cache management guide:**
```markdown
# Earnings Cache Management

This directory contains the earnings date cache used by the FF scanner for fast pre-filtering.

## Cache File

**Location:** `.cache/earnings.db`
**Type:** SQLite database
**Purpose:** Persistent storage of earnings dates to avoid repeated API calls

## Cache Schema

```sql
CREATE TABLE earnings (
    symbol TEXT PRIMARY KEY,          -- Stock/futures symbol (e.g., 'AAPL', '/ES')
    next_earnings_date TEXT,          -- Next earnings date (YYYY-MM-DD) or NULL
    last_updated TEXT,                -- ISO timestamp of last fetch
    data_source TEXT                  -- 'yahoo' | 'tastytrade'
)
```

## Cache Behavior

**Automatic invalidation:**
- If `next_earnings_date` is in the PAST → re-fetch from API
- If `next_earnings_date` is in the FUTURE → use cached value (no TTL)

**Data sources:**
1. Yahoo Finance (primary, ~100ms per symbol)
2. TastyTrade API (fallback, ~500ms per symbol)

## Manual Cache Management

**Clear entire cache:**
```bash
rm .cache/earnings.db
```
The scanner will rebuild the cache automatically on next run.

**Inspect cache contents:**
```bash
sqlite3 .cache/earnings.db "SELECT * FROM earnings LIMIT 10;"
```

**Cache statistics:**
```bash
sqlite3 .cache/earnings.db "SELECT COUNT(*) FROM earnings;"
sqlite3 .cache/earnings.db "SELECT data_source, COUNT(*) FROM earnings GROUP BY data_source;"
```

## Troubleshooting

**Problem: Cache seems slow**
- Check file size: `ls -lh .cache/earnings.db`
- If >100MB, consider clearing old entries
- Solution: `rm .cache/earnings.db` (rebuild from scratch)

**Problem: "Database locked" error**
- Multiple scanner instances may be accessing cache simultaneously
- Solution: Wait for other processes to finish, or kill them

**Problem: Stale earnings dates**
- Cache should auto-refresh when dates pass
- For manual refresh: `rm .cache/earnings.db`

## Performance

**Cache hit performance:**
- Lookup time: <10ms per symbol
- 1000 symbols (cache hits): <1 second

**Cache miss performance:**
- Yahoo Finance: ~100ms per symbol
- TastyTrade fallback: ~500ms per symbol
- 1000 symbols (cold start): <30 seconds

## Version History

- v2.1 (2025-10-19): Initial cache implementation
```

**Files affected:**
- `scripts/README_TT.md` (updated)
- `CLAUDE.md` (updated)
- `.cache/README.md` (NEW)

## Dependencies

- [ ] Task 002 completed (know how pre-filter works)
- [ ] Task 003 completed (know fallback behavior)
- [ ] Task 004 completed (know CSV schema change)
- [ ] Task 005 completed (know CLI flag removal)

## Effort Estimate

- **Size:** M (Medium)
- **Hours:** 4-6 hours
- **Parallel:** true (documentation-only, no code conflicts)

**Breakdown:**
- Update README_TT.md: 2 hours
- Update CLAUDE.md: 1 hour
- Create .cache/README.md: 1 hour
- Review and polish: 1 hour
- User testing (check clarity): 1 hour

## Definition of Done

- [ ] All 3 documentation files updated
- [ ] CSV schema examples show 29 columns
- [ ] CLI examples remove --skip-earnings
- [ ] Performance claims are accurate (verified by Task 007)
- [ ] Troubleshooting section tested (manually clear cache, verify instructions work)
- [ ] Reviewed by another developer (or self-review for clarity)

## Testing Notes

**Documentation testing:**
1. Follow cache clearing instructions → Verify cache rebuilds
2. Run example commands → Verify all work (no --skip-earnings)
3. Check CSV schema example → Verify matches actual output
4. Follow troubleshooting steps → Verify solutions work

**Clarity checklist:**
- [ ] User can understand performance improvements without reading code
- [ ] Cache management steps are clear and actionable
- [ ] Troubleshooting covers common issues
- [ ] Migration from v2.0 is explained

## Notes

**Coordinate with Task 007:** Performance claims in docs should match actual benchmarks from Task 007. Update docs if benchmarks reveal different numbers.

**Version increment:** All docs should reference v2.1 consistently.

**Keep it simple:** Avoid over-explaining implementation details. Focus on user-facing behavior and benefits.
