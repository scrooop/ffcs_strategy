---
name: Create Migration Guide v2.2 → v3.0
status: open
created: 2025-10-20T17:48:36Z
updated: 2025-10-20T18:23:15Z
github: https://github.com/scrooop/ffcs_strategy/issues/44
depends_on: [41, 42, 43]
parallel: true
conflicts_with: []
---

# Task: Create Migration Guide v2.2 → v3.0

## Description

Create standalone migration guide with pandas code examples showing how to update CSV parsers from v2.2 (40 columns) to v3.0 (32 columns). Include column mapping reference table and breaking changes documentation.

**Priority:** LOW (Phase 5 - Documentation & Testing)

**Depends On:** Tasks 41, 42 (CSV schema finalized), Task 43 (documentation structure)

## Acceptance Criteria

- [ ] Migration guide document created (Markdown format)
- [ ] Pandas code examples provided (v2.2 vs v3.0 parsing)
- [ ] Column mapping reference table included
- [ ] Breaking changes clearly documented
- [ ] Common migration issues addressed (e.g., column not found errors)
- [ ] Guide tested with real v2.2 and v3.0 CSV files

## Technical Details

### Files to Create
- `.claude/epics/output-csv-terminal-flags/migration-guide-v2.2-to-v3.0.md`

### Implementation Approach

**Migration Guide Structure:**

```markdown
# Migration Guide: CSV Schema v2.2 → v3.0

## Overview

The FF scanner CSV schema has been refactored in v3.0 to eliminate redundant columns and improve clarity. This guide helps you update existing CSV parsing code.

**Key Changes:**
- Column count: 40 → 32 (20% reduction)
- Eliminated: 8 `atm_*` columns (redundant namespace)
- Renamed: `call_strike` → `strike`, `call_delta` → `delta`, `call_ff` → `ff`
- Reordered: Trading parameters grouped together (DTEs, strikes, FF)

## Breaking Changes

### 1. Column Renaming (3 columns)
- `call_strike` → `strike` (unified namespace)
- `call_delta` → `delta` (unified namespace)
- `call_ff` → `ff` (unified namespace)

### 2. Removed Columns (8 columns)
- `atm_strike` → Use `strike` (unified)
- `atm_delta` → Use `delta` (unified)
- `atm_ff` → Use `ff` (unified)
- `atm_iv_front` → Use `call_front_iv` (unified)
- `atm_iv_back` → Use `call_back_iv` (unified)
- `atm_fwd_iv` → Use `call_fwd_iv` (unified)
- `atm_iv_source_front` → Use `iv_source_call_front` (unified)
- `atm_iv_source_back` → Use `iv_source_call_back` (unified)

### 3. Column Reordering
Trading parameters now grouped: DTEs → Expirations → Strikes → FF

## Migration Examples

### Example 1: Filter ATM Opportunities

**v2.2 Code:**
\`\`\`python
import pandas as pd

# Read v2.2 CSV (40 columns)
df = pd.read_csv("scan_v2.2.csv")

# Filter ATM opportunities
atm_opps = df[df["structure"] == "atm-call"]
atm_opps = atm_opps[atm_opps["atm_ff"] >= 0.23]  # OLD COLUMN NAME
atm_opps = atm_opps.sort_values("atm_ff", ascending=False)

# Access strike and delta
for idx, row in atm_opps.iterrows():
    strike = row["atm_strike"]  # OLD COLUMN NAME
    delta = row["atm_delta"]    # OLD COLUMN NAME
    ff = row["atm_ff"]          # OLD COLUMN NAME
    print(f"{row['symbol']}: strike={strike}, delta={delta}, FF={ff:.2f}")
\`\`\`

**v3.0 Code:**
\`\`\`python
import pandas as pd

# Read v3.0 CSV (32 columns)
df = pd.read_csv("scan_v3.0.csv")

# Filter ATM opportunities
atm_opps = df[df["structure"] == "atm-call"]
atm_opps = atm_opps[atm_opps["ff"] >= 0.23]  # NEW COLUMN NAME
atm_opps = atm_opps.sort_values("ff", ascending=False)

# Access strike and delta
for idx, row in atm_opps.iterrows():
    strike = row["strike"]  # NEW COLUMN NAME
    delta = row["delta"]    # NEW COLUMN NAME
    ff = row["ff"]          # NEW COLUMN NAME
    print(f"{row['symbol']}: strike={strike}, delta={delta}, FF={ff:.2f}")
\`\`\`

### Example 2: Filter Double Calendars

**v2.2 Code:**
\`\`\`python
# Filter double calendars
double_opps = df[df["structure"] == "double"]
double_opps = double_opps[double_opps["min_ff"] >= 0.20]

# Access call and put strikes
for idx, row in double_opps.iterrows():
    call_strike = row["call_strike"]  # OLD COLUMN NAME
    put_strike = row["put_strike"]    # UNCHANGED
    print(f"{row['symbol']}: call={call_strike}, put={put_strike}")
\`\`\`

**v3.0 Code:**
\`\`\`python
# Filter double calendars
double_opps = df[df["structure"] == "double"]
double_opps = double_opps[double_opps["min_ff"] >= 0.20]

# Access call and put strikes
for idx, row in double_opps.iterrows():
    call_strike = row["strike"]      # NEW COLUMN NAME (call strike)
    put_strike = row["put_strike"]   # UNCHANGED
    print(f"{row['symbol']}: call={call_strike}, put={put_strike}")
\`\`\`

### Example 3: Export Subset of Columns

**v2.2 Code:**
\`\`\`python
# Export trading parameters only
cols = ["symbol", "front_expiry", "back_expiry", "atm_strike", "atm_ff"]
export_df = atm_opps[cols]
export_df.to_csv("atm_trades_v2.2.csv", index=False)
\`\`\`

**v3.0 Code:**
\`\`\`python
# Export trading parameters only
cols = ["symbol", "front_expiry", "back_expiry", "strike", "ff"]  # UPDATED
export_df = atm_opps[cols]
export_df.to_csv("atm_trades_v3.0.csv", index=False)
\`\`\`

## Column Mapping Reference

| v2.2 Column (40 total) | v3.0 Column (32 total) | Structure | Notes |
|------------------------|------------------------|-----------|-------|
| `atm_strike` | `strike` | ATM | Unified namespace |
| `atm_delta` | `delta` | ATM | Unified namespace |
| `atm_ff` | `ff` | ATM | Unified namespace |
| `atm_iv_front` | `call_front_iv` | ATM | Use call IV columns |
| `atm_iv_back` | `call_back_iv` | ATM | Use call IV columns |
| `atm_fwd_iv` | `call_fwd_iv` | ATM | Use call IV columns |
| `atm_iv_source_front` | `iv_source_call_front` | ATM | Unified tracking |
| `atm_iv_source_back` | `iv_source_call_back` | ATM | Unified tracking |
| `call_strike` | `strike` | Double | Renamed (call strike) |
| `call_delta` | `delta` | Double | Renamed (call delta) |
| `call_ff` | `ff` | Double | Renamed (call FF) |
| `put_strike` | `put_strike` | Double | UNCHANGED |
| `put_delta` | `put_delta` | Double | UNCHANGED |
| `put_ff` | `put_ff` | Double | UNCHANGED |
| `min_ff` | `min_ff` | Both | UNCHANGED |
| `combined_ff` | `combined_ff` | Double | UNCHANGED |

## Common Migration Issues

### Issue 1: KeyError: 'atm_ff'
**Cause:** Trying to access removed column
**Fix:** Use unified column name `ff` instead

\`\`\`python
# ERROR
ff = row["atm_ff"]

# FIX
ff = row["ff"]
\`\`\`

### Issue 2: KeyError: 'call_strike' (for ATM)
**Cause:** ATM rows don't populate `call_strike` in v2.2, but v3.0 uses unified `strike`
**Fix:** Use `strike` for both ATM and double

\`\`\`python
# v2.2 (structure-specific columns)
if row["structure"] == "atm-call":
    strike = row["atm_strike"]
else:
    strike = row["call_strike"]

# v3.0 (unified column)
strike = row["strike"]  # Works for both ATM and double
\`\`\`

### Issue 3: Wrong column count when reading CSV
**Cause:** CSV has 32 columns (v3.0) but code expects 40 (v2.2)
**Fix:** Update column list or use pandas auto-detection

\`\`\`python
# Don't hardcode column count
df = pd.read_csv("scan.csv", names=OLD_40_COLUMNS)  # ERROR

# Let pandas auto-detect
df = pd.read_csv("scan.csv")  # CORRECT
\`\`\`

## Testing Your Migration

### 1. Verify Column Names
\`\`\`python
# Check available columns
print(df.columns.tolist())

# Should show 32 columns, including: 'strike', 'delta', 'ff'
# Should NOT show: 'atm_strike', 'atm_delta', 'atm_ff'
\`\`\`

### 2. Test with Sample Data
\`\`\`python
# Test ATM parsing
atm_row = df[df["structure"] == "atm-call"].iloc[0]
assert "ff" in atm_row.index, "Missing 'ff' column"
assert pd.isna(atm_row["put_strike"]) or atm_row["put_strike"] == "", "ATM should have empty put_strike"

# Test double parsing
double_row = df[df["structure"] == "double"].iloc[0]
assert "ff" in double_row.index, "Missing 'ff' column"
assert double_row["put_strike"] != "", "Double should have put_strike"
\`\`\`

## Need Help?

If you encounter migration issues not covered here:
1. Check CLAUDE.md for full v3.0 schema documentation
2. Compare your v2.2 CSV with v3.0 CSV side-by-side
3. Use the column mapping table to find new column names
```

### Key Considerations
- Focus on practical code examples (not just theory)
- Address common KeyError exceptions
- Show side-by-side v2.2 vs v3.0 code
- Test migration guide with real CSV files

## Dependencies

**Internal:**
- [x] Task #41 (CSV Refactor) must be complete (schema finalized)
- [x] Task #42 (Column Reordering) must be complete (final column order)
- [x] Task #43 (Documentation) must be complete (schema documented)

## Effort Estimate

- **Size:** S (Small)
- **Hours:** 3-4 hours
- **Parallel:** true (no conflicts)

### Breakdown:
- Write migration guide: 2 hours
- Create pandas examples: 1 hour
- Test with real CSV files: 1 hour

## Definition of Done

- [ ] Migration guide document created
- [ ] 3+ pandas code examples provided (v2.2 vs v3.0)
- [ ] Column mapping table complete (all changed columns)
- [ ] Common migration issues documented with fixes
- [ ] Guide tested with real v2.2 and v3.0 CSV files
- [ ] All code examples run without errors
